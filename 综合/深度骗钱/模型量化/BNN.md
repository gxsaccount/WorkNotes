## 1.前言  ##  
float32的构成:  

    符号位[ ] + 指数位[ ] *8 + 尾数[ ]*23  
    
float32一共有2^23尾数,10^6 < 2^23 < 10^8,所以一般可以精确的表示6位有效数字,但是无法表示8位游侠数字  
然后完成一个浮点数的加减运算至少有如下过程：

    1.检查操作数，即如果有一个参与运算的数为0，那么直接得出结果。
    2.比较阶码大小完成对阶。
    3.对尾数进行加或减运算。
    4.将结果规格化并进行舍入处理  
CNN默认使用float32,会占用大量的内存和计算资源.  


## 2.BNN原理 ##  
在训练BNN时，我们要把网络层的权重和输出值设为1或者-1，下面是论文提出的2种二值化方法。    
方法一:  
第一种是直接将大于等于0的参数设置为1，小于0的设置为-1  

方法二:   
第二种是将绝对值大于1的参数设为1，将绝对值小于1的参数根据距离+/-1的远近按概率随机置为+/-1：  

第二种方法似乎更加合理，但它也引入了按概率分布的随机比特数，因此硬件实现会消耗很多时间，所以通常会选定第一种方法来对权重和输出值进行量化。  
