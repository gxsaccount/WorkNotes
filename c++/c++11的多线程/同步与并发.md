1.利用sleep释放cpu资源  

    bool flag;
    std::mutex m;
    void wait_for_flag(){
        std::unique_lock<std::mutex> lk(m);
        while (!flag){
            lk.unlock();                                                 //	1	解锁互斥量
            std::this_thread::sleep_for(std::chrono::milliseconds(100)); //	2	休眠100ms
            lk.lock();                                                   //	3	再锁互斥量
        }
    }
    
 2.利用std::condition_variable和std::condition_variable_any等待条件达成  
  
    std::mutex mut;
    std::queue<data_chunk> data_queue; //	1.两个线程之间传递数据的队列
    std::condition_variable data_cond;
    void data_preparation_thread(){
        while (more_data_to_prepare()){
            data_chunk const data = prepare_data();
            std::lock_guard<std::mutex> lk(mut);//数据准备好时上锁
            data_queue.push(data);  //	2 将数据安全的压入队列
            data_cond.notify_one(); //	3 通知wait在data_cond上的线程
        }
    }
    void data_processing_thread(){
        while (true){
            std::unique_lock<std::mutex> lk(mut); //	4
            data_cond.wait(lk, [] { return !data_queue.empty(); }); //	5 等待在data_cond上，检查条件判断是否上锁
            data_chunk data = data_queue.front();
            data_queue.pop();
            lk.unlock(); //	6执行完解锁
            process(data);
            if (is_last_chunk(data))
                break;
        }
    }
    
wait()函数传入锁和检查条件，根据条件判断是否给锁的互斥量加锁。不加锁就阻塞，等待notify_one()/notify_all()通知，重新获取互斥锁,并且对条件再次检查。  
等待中的线程必须在等待期间解锁互斥量,并在这这之后对互斥量再次上锁,而std::lock_guard没有这么灵活。  

3.有返回值的线程：std::async//std::future<>与std::shared_future<>  
std::future<>与std::shared_future<>对应std::unique_ptr和	std::shared_ptr。  
std::future只能与一个指定事件相关联，std::shared_future能关联多个事件。  
与std::thread对象等待的方式不同,std::async会返回一个std::future对象。其他参数等与std::thread一样

    #include <future>
    #include <iostream>
    int find_the_answer_to_ltuae();
    void do_other_stuff();
    int main(){
        std::future<int> the_answer = std::async(find_the_answer_to_ltuae);//线程开启
        do_other_stuff();
        std::cout << "The	answer	is	" << the_answer.get() << std::endl;//获得返回值
    }


<table>
  <td >类型/命名空间</td>
  <td  >函数</td>
  <td>返回值</td>
 </tr>
 <tr >
  <td rowspan="2">std::this_thread[namespace]</td>
  <td>sleep_for(duration)</td>
  <td rowspan="2">N/A
    </td>
 </tr>
 <tr >
  <td >sleep_until(time_point)</td>
 </tr>
 <tr >
  <td rowspan="2">std::condition_variable 或
    std::condition_variable_any</td>
  <td  >wait_for(lock, duration)
    </td>
  <td>std::cv_status:</td>
 </tr>
 <tr >
  <td >wait_until(lock,time_point)
    </td>
  <td >std::cv_status:</td>
 </tr>
 <tr >
  <td rowspan="2" ></td>
  <td  >wait_for(lock, duration,
    predicate)</td>
  <td rowspan="2" >bool
  —— 当唤醒时，返回谓果
    </td>
 </tr>
 <tr >
  <td>wait_until(lock,
  duration,predicate)
    </td>
 </tr>
 <tr >
  <td rowspan="2" >std::timed_mutex 或
    std::recursive_timed_mutex</td>
  <td>try_lock_for(duration)</td>
  <td rowspan="2" >bool ——
  获取锁时返回true，否则
    返回fasle</td>
 </tr>
 <tr >
  <td >try_lock_until(time_point)</td>
 </tr>
 <tr >
  <td rowspan="2" >std:unique_lock&lt;TimedLockedable&gt;</td>
  <td>unique_lock(lockable, duration)</td>
  <td>N/A —— 对新构建的对象调用
    owns_lock();
    </td>
 </tr>
 <tr >
  <td >unique_lock(lockable,
    time_point)
    </td>
  <td >当获取锁时返回true，否则返回
    false
    </td>
 </tr>
 <tr >
  <td rowspan="2" ></td>
  <td>try_lock_for(duration)</td>
  <td rowspan="2"  >bool —— 当获取锁时返回true，否
    则返回false</td>
 </tr>
 <tr >
  <td >try_lock_until(time_point)</td>
 </tr>
 <tr height="37" >
  <td rowspan="4">std::future&lt;ValueType&gt;或
    std::shared_future&lt;ValueType&gt;
    </td>
  <td>wait_for(duration)</td>
  <td>当等待超时，返回
    std::future_status::t</td>
 </tr>
 <tr >
  <td rowspan="3" >wait_until(time_point)</td>
  <td></td>
 </tr>
 <tr >
  <td height="37" >当“期望”准备就绪时，返回
    std::future_status::r</td>
 </tr>
 <tr >
  <td height="55" >当“期望”持有一个为启动的延迟函
    数，返回
    std::future_status::d</td>
 </tr>
</table>
